# 🎫 Concert Queue System - Incident Report

## 📍 현상 (Incident Overview)

### ▪️ 타임라인
- **장애 시작 시각**: 2025-06-03 13:42 (KST)
- **최초 감지 시각**: 2025-06-03 13:43 (k6 모니터링 에러율 알람)
- **완전 복구 시각**: 2025-06-03 14:11 (서비스 안정화 확인)
- **총 장애 지속 시간**: 약 29분

### ▪️ 영향 범위
- `/queue/enter` API 요청 중 일부 실패 발생
- Kafka 토픽 전송은 정상이나, 응답 지연 및 타임아웃 증가

### ▪️ 고객 영향도 (Business Impact)
- **대기열 진입 실패율 0.03% 기록** (7600명 동시 요청 시)
- 일부 사용자는 "요청 시간 초과" 메시지 수신
- 대기열 대기 시간이 지연되어 사용자 이탈 가능성 존재
- 결제 전환율에 악영향 가능

---

## 🛠 조치 내용

### ▪️ 장애 원인
- Docker 기반 테스트 환경에서 `host.docker.internal` 네트워크 병목 발생
- 테스트 시점에서 InfluxDB Push 지연 → 모니터링 대시보드 반영 지연
- 서버 수신 포트 backlog 초과 및 CPU 스파이크

### ▪️ 해소 타임라인
| 시간           | 조치 내용                           |
|----------------|------------------------------------|
| 13:43          | k6 에러율 알람 Slack으로 감지            |
| 13:45          | InfluxDB I/O 지연 로그 확인               |
| 13:50          | 서버 자원 사용량 확인, backlog 설정 확인 |
| 14:03          | Docker 내 Kafka Producer 버퍼 조정       |
| 14:10          | 모니터링 복구 확인 및 안정화                |
| 14:11          | 장애 종료 처리 및 재발 방지 점검 완료       |

### ▪️ 실제 단기 대응책
- 서버 포트 backlog 증가 설정
- Kafka Producer 전송 지연 시 retry 로직 적용
- InfluxDB 쓰기 버퍼 및 Push Interval 조정

### ▪️ 후속 대응 계획
- 테스트 환경 개선: `host.docker.internal` → 내부 브릿지 네트워크 전환
- InfluxDB → Prometheus 전환 고려
- 실 서비스 환경에서도 TPS 부하 시뮬레이션 자동화 배치 검토

---

## 🔎 분석 (Root Cause Analysis)

### ▪️ 5 Whys

1. **왜** 일부 요청이 실패했는가?  
   → `i/o timeout`, `EOF` 등 네트워크 연결 실패 발생

2. **왜** 네트워크 연결 실패가 발생했는가?  
   → 7600 VU에서 Docker의 네트워크 인터페이스 `host.docker.internal` 병목 발생

3. **왜** 병목이 발생했는가?  
   → 동시에 수천 개의 요청이 단일 인터페이스와 포트로 집중됨

4. **왜** 단일 포트에 집중되었는가?  
   → Docker 테스트 환경 설정상 포트 분산 및 네트워크 제한 없음

5. **왜** 테스트 환경 설정이 실환경 대비 제한적이었는가?  
   → 초기 테스트 설정에서 Docker 간 네트워크 세분화 미흡

---

## 🧩 대응 방안

| 항목              | 개선안                                                         |
|-------------------|----------------------------------------------------------------|
| 네트워크 병목      | Docker 간 전용 브릿지 네트워크 설정, 로컬 인터페이스 사용 자제           |
| 모니터링 병목      | InfluxDB write throughput 조정, 필드/태그 최소화, Prometheus 전환 검토 |
| 시스템 수용량 한계 | backlog 설정 확대, CPU reservation 설정 강화                         |
| 재현 가능한 테스트 | CI/CD 파이프라인 내 자동 부하 테스트 통합                             |
| 장애 복구 자동화   | 실패율 감지 시 서버 상태 확인 및 재시작 스크립트 자동화                 |

---

## 📬 결론 및 요약

이번 장애는 **성능 테스트 중 Docker 기반 환경의 네트워크 병목 및 모니터링 병목**으로 인해 **일시적인 요청 실패와 응답 지연**이 발생한 사례입니다. 실환경과 유사한 테스트 환경 구성의 중요성이 재확인되었으며, TPS 임계점 재설정 및 Kafka 메시지 처리 성능은 안정적이라는 점도 확인할 수 있었습니다.

장애 복구 이후 테스트 환경 및 모니터링 체계를 개선하고, 테스트 자동화를 강화하여 유사한 장애 발생 가능성을 최소화할 예정입니다.
